{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lsBUOPQeGI4Y"
   },
   "source": [
    "## TF Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3l7cSgzJnzcL"
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import glob\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D,BatchNormalization,Activation,Dropout,AveragePooling2D,MaxPooling2D,Flatten,Dense,Input,Concatenate\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xZGUWiemtsV3",
    "outputId": "27ebecc4-4b6a-4bc9-afdb-edef103af0e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sB02tSiKmJot"
   },
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IHjK0Xt65WHp"
   },
   "outputs": [],
   "source": [
    "#write a function to download the dataset from tenserflow datasets\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def get_data(x,preprocess=False):\n",
    "  (X_train, y_train), (X_test, y_test) = x.load_data()\n",
    "  num_classes = len(np.unique(y_train))\n",
    "  X_train, Y_train = shuffle(X_train, y_train)\n",
    "  X_test, Y_test = shuffle(X_test, y_test)\n",
    "\n",
    "  if preprocess:\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        X_train /= 255\n",
    "        X_test /= 255\n",
    "  \n",
    "  #Y_train = to_categorical(y_train, num_classes)\n",
    "  #Y_test = to_categorical(y_test, num_classes)\n",
    "  return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "mg-5iUcLki7r",
    "outputId": "160f5676-3bb0-45b3-f0e4-d04869b70cf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 9s 0us/step\n",
      "(50000, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(50000,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, Y_train, X_test, Y_test=get_data(cifar10)\n",
    "print(Y_train.shape)\n",
    "print(type(Y_train))\n",
    "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
    "len_train, len_test = len(X_train), len(X_test)\n",
    "Y_train = Y_train.astype('int64').reshape(len_train)\n",
    "print(Y_train.shape)\n",
    "print(type(Y_train))\n",
    "Y_test = Y_test.astype('int64').reshape(len_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QFuedj9aiYcV"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def _bytes_feature(value):\n",
    "\t\"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "\treturn tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "\t\"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "\treturn tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "\t\"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "\treturn tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def serialize_function(x, y):\n",
    "\texample = tf.train.Example(features=tf.train.Features(\n",
    "\t\t\t\t\tfeature={\n",
    "\t\t\t\t\t\t\t'image': _bytes_feature(tf.compat.as_bytes(x.tostring())),\n",
    "\t\t\t\t\t\t\t'label': _int64_feature(int(y))\n",
    "\t\t\t\t\t}))\n",
    "\treturn example.SerializeToString()\n",
    "\n",
    "\n",
    "def convert_to_tfrecord(data_set, file_name):\n",
    "\twith tf.python_io.TFRecordWriter(file_name) as record_writer:\n",
    "\t\tfor x, y in data_set:\n",
    "\t\t\tif isinstance(x, (np.ndarray, np.generic)) and isinstance(y, (np.ndarray, np.generic)):\n",
    "\t\t\t\trecord = serialize_function(x, y)\n",
    "\t\t\telse:\n",
    "\t\t\t\trecord = serialize_function(x.numpy(), y.numpy())\n",
    "\t\t\trecord_writer.write(record)\n",
    "\t\tprint(f\"TFRecord id created at path : '{file_name}', Done\")\n",
    "\n",
    "\n",
    "def parser(record, shape=[32, 32, 3], num_of_class=10):\n",
    "\tfeature_description = {\n",
    "\t'image': tf.FixedLenFeature([], tf.string, default_value=''),\n",
    "\t'label': tf.FixedLenFeature([], tf.int64, default_value=0)\n",
    "\t# 'feature2': tf.FixedLenFeature([], tf.string, default_value=''),\n",
    "\t# 'feature3': tf.FixedLenFeature([], tf.float32, default_value=0.0),\n",
    "\t\t}\n",
    "\tparsed = tf.parse_single_example(record, feature_description)\n",
    "\timage = tf.decode_raw(parsed[\"image\"], tf.uint8)\n",
    "\timage = tf.cast(image, tf.float32)\n",
    "\timage = tf.reshape(image, shape=shape)\n",
    "\tlabel = tf.cast(parsed[\"label\"], tf.int32)\n",
    "\tlabel = tf.one_hot(label, num_of_class, dtype=tf.int32)\n",
    "\treturn image, label\n",
    "\n",
    "\n",
    "class CreateTFRecord(object):\n",
    "    \"\"\"docstring for CreateTFRecord\"\"\"\n",
    "    '''\n",
    "    EXP.\n",
    "    data_to_write = zip(x_train, y_train)\n",
    "    file name = 'train.tfrecord'\n",
    "    '''\n",
    "    def __init__(self, data_to_write, file_name):\n",
    "        super().__init__()\n",
    "        self.data_to_write = data_to_write\n",
    "        self.file_name = file_name\n",
    "        convert_to_tfrecord(self.data_to_write, self.file_name)\n",
    "\n",
    "class Get_dataset(object):\n",
    "\tdef __init__(self, file_name , buffer_size=1024, seed=1, batch_size=32, GPU_buffer_size = None):\n",
    "\t\tself.file_name = file_name\n",
    "\t\tself.buffer_size=buffer_size\n",
    "\t\tself.seed=seed\n",
    "\t\tself.batch_size=batch_size\n",
    "\t\tself.GPU_buffer_size = GPU_buffer_size\n",
    "\t\tinput_foo(self.file_name, self.buffer_size, self.seed, self.batch_size, self.GPU_buffer_size)\n",
    "# CreateTFRecord(\"kk.tfrecord\", \"kk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sk7uq-4xGQpF"
   },
   "source": [
    "## TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819
    },
    "colab_type": "code",
    "id": "Mrvz40flLT4k",
    "outputId": "d01c938c-dc20-49ab-d3ec-f94702d74d65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/kkrunal77/data_science_utils/tarball/master\n",
      "\u001b[?25l  Downloading https://github.com/kkrunal77/data_science_utils/tarball/master\n",
      "\u001b[K     - 10kB 11.1MB/s\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from data-science-utils==0.0.0) (1.16.5)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow in /usr/local/lib/python3.6/dist-packages (from data-science-utils==0.0.0) (1.14.0)\n",
      "Collecting tensorflow_datasets (from data-science-utils==0.0.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/34/ff424223ed4331006aaa929efc8360b6459d427063dc59fc7b75d7e4bab3/tensorflow_datasets-1.2.0-py3-none-any.whl (2.3MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3MB 41.6MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->data-science-utils==0.0.0) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->data-science-utils==0.0.0) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->data-science-utils==0.0.0) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->data-science-utils==0.0.0) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->data-science-utils==0.0.0) (0.1.7)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->data-science-utils==0.0.0) (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->data-science-utils==0.0.0) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow->data-science-utils==0.0.0) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow->data-science-utils==0.0.0) (0.33.6)\n",
      "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->data-science-utils==0.0.0) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->data-science-utils==0.0.0) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->data-science-utils==0.0.0) (3.7.1)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->data-science-utils==0.0.0) (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->data-science-utils==0.0.0) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: psutil in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->data-science-utils==0.0.0) (5.4.8)\n",
      "Requirement already satisfied, skipping upgrade: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->data-science-utils==0.0.0) (2.2.1)\n",
      "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->data-science-utils==0.0.0) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->data-science-utils==0.0.0) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->data-science-utils==0.0.0) (4.28.1)\n",
      "Requirement already satisfied, skipping upgrade: attrs in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->data-science-utils==0.0.0) (19.1.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->data-science-utils==0.0.0) (0.14.0)\n",
      "Requirement already satisfied, skipping upgrade: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->data-science-utils==0.0.0) (0.3.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow->data-science-utils==0.0.0) (41.2.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow->data-science-utils==0.0.0) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow->data-science-utils==0.0.0) (0.15.6)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow->data-science-utils==0.0.0) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets->data-science-utils==0.0.0) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets->data-science-utils==0.0.0) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets->data-science-utils==0.0.0) (2019.6.16)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets->data-science-utils==0.0.0) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow_datasets->data-science-utils==0.0.0) (1.6.0)\n",
      "Building wheels for collected packages: data-science-utils\n",
      "  Building wheel for data-science-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for data-science-utils: filename=data_science_utils-0.0.0-cp36-none-any.whl size=3777 sha256=de2c99c15ee573d8bc716357ca576359ddf7c90376e132bfb7b987331e856cff\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-x41brhk6/wheels/72/1a/9f/4d1aadec4afb9693f42c521c5be90d606f56f435ba21e38756\n",
      "Successfully built data-science-utils\n",
      "Installing collected packages: tensorflow-datasets, data-science-utils\n",
      "Successfully installed data-science-utils-0.0.0 tensorflow-datasets-1.2.0\n"
     ]
    }
   ],
   "source": [
    "# installing data_science_utils repo.\n",
    "pip install --upgrade --upgrade-strategy only-if-needed https://github.com/kkrunal77/data_science_utils/tarball/master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "vUetcFc2LWlT",
    "outputId": "6a9eb756-2098-4e10-90f2-46b4a6284187"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/data/TFRecords/TFrecord.py:30: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "TFRecord id created at path : 'train.tfrecord', Done\n",
      "TFRecord id created at path : 'test.tfrecord', Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<data.TFRecords.TFrecord.CreateTFRecord at 0x7f893b590da0>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.imports import *\n",
    "\n",
    "TFrecord.CreateTFRecord(zip(X_train, Y_train), 'train.tfrecord')\n",
    "TFrecord.CreateTFRecord(zip(X_test, Y_test), 'test.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rAAhbNGFZxwo",
    "outputId": "d4158778-d769-479e-d734-4754c075f709"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*64*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E32xNrNUVaDy"
   },
   "outputs": [],
   "source": [
    "#tuning pipline\n",
    "\n",
    "def input_foo(filenames, buffer_size, seed, batch_size, GPU_buffer_size):\n",
    "    \n",
    "\tdataset = tf.data.TFRecordDataset(filenames=filenames, buffer_size=buffer_size)\n",
    "\n",
    "\tdataset = dataset.apply(\n",
    "\t\ttf.data.experimental.shuffle_and_repeat(buffer_size=buffer_size,\n",
    "\t\t\t\t\t\t\t\t\t\t   seed=seed)\n",
    "\t\t)\n",
    "\tdataset = dataset.apply(\n",
    "\t\ttf.data.experimental.map_and_batch(\n",
    "\t\t\t\t\t\t\t\t  map_func=parser,\n",
    "\t\t\t\t\t\t\t\t  batch_size=batch_size,\n",
    "\t\t\t\t\t\t\t\t  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\t\t)\n",
    "\tdataset = dataset.apply(tf.data.experimental.prefetch_to_device('/GPU:0', buffer_size=GPU_buffer_size))\n",
    "\tdataset = dataset.prefetch(8)\n",
    "\treturn dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "feTwg4IpLjvy"
   },
   "outputs": [],
   "source": [
    "# test_dataset = TFrecord.input_foo(filenames='test.tfrecord', buffer_size=1024, seed=2, batch_size=64, GPU_buffer_size=None)\n",
    "# train_dataset = TFrecord.input_foo(filenames='train.tfrecord', buffer_size=1024, seed=2, batch_size=64, GPU_buffer_size=None)\n",
    "\n",
    "test_dataset = input_foo(filenames='test.tfrecord', buffer_size=8*128*128, seed=50, batch_size=64, GPU_buffer_size=None)\n",
    "train_dataset = input_foo(filenames='train.tfrecord', buffer_size=8*128*128, seed=50, batch_size=64, GPU_buffer_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uS9QBUVAxpcu"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r0sy4YGCH5vC"
   },
   "source": [
    "##Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UNHw6luQg3gc",
    "outputId": "22bccd3b-8439-4788-f116-da1091191df5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
    "# backend\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dsO_yGxcg5D8"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 64 \n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "l = 6 \n",
    "num_filter = 32\n",
    "compression = 0.5\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ee-sge5Kg7vr"
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def add_denseblock(input, num_filter = 64, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l):\n",
    "        BatchNorm = BatchNormalization()(temp)\n",
    "        relu = Activation('relu')(BatchNorm)\n",
    "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        \n",
    "        temp = concat\n",
    "        \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOP6IPsGhBwb"
   },
   "outputs": [],
   "source": [
    "def add_transition(input, num_filter = 32, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "        Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0RaKFpubhDIC"
   },
   "outputs": [],
   "source": [
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = Flatten()(AvgPooling)\n",
    "    output = Dense(num_classes, activation='softmax')(flat)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anPCpQWhhGb7"
   },
   "outputs": [],
   "source": [
    "num_filter = 32\n",
    "dropout_rate = 0.2\n",
    "l = 6\n",
    "input = Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
    "\n",
    "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
    "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "#Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "#Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "Last_Block = add_denseblock(Second_Transition,  num_filter, dropout_rate)\n",
    "output = output_layer(Last_Block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1kFh7pdxhNtT",
    "outputId": "b717f6e7-e8f8-4f5a-fe66-12dff94c6236"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 32)   128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 16)   4608        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 16)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 48)   0           conv2d[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 48)   192         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 48)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   6912        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 16)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 64)   0           concatenate[0][0]                \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 64)   256         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   9216        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 16)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 80)   0           concatenate_1[0][0]              \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 80)   320         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 16)   11520       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 16)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 96)   0           concatenate_2[0][0]              \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 96)   384         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 96)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 16)   13824       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 16)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 112)  0           concatenate_3[0][0]              \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 112)  448         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 112)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 16)   16128       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 16)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 128)  0           concatenate_4[0][0]              \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 128)  512         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 16)   2048        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 16)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 16)   0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 16)   64          average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 16)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 16)   2304        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 16, 16, 16)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 16, 16, 32)   0           average_pooling2d[0][0]          \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 16)   4608        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 16, 16, 16)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 16, 16, 48)   0           concatenate_6[0][0]              \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 48)   192         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 48)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 16)   6912        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16, 16, 16)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 16, 16, 64)   0           concatenate_7[0][0]              \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 64)   256         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 16)   9216        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 16, 16, 16)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 16, 16, 80)   0           concatenate_8[0][0]              \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 80)   320         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 80)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 16)   11520       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 16, 16, 16)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 16, 16, 96)   0           concatenate_9[0][0]              \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 96)   384         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 96)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 16)   13824       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 16, 16, 16)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 16, 16, 112)  0           concatenate_10[0][0]             \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 112)  448         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 112)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 16)   1792        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16, 16, 16)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 16)     0           dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 16)     64          average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 16)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 16)     2304        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 8, 8, 16)     0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 8, 8, 32)     0           average_pooling2d_1[0][0]        \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 32)     128         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 32)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 16)     4608        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 8, 8, 16)     0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 8, 8, 48)     0           concatenate_12[0][0]             \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 48)     192         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 48)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 16)     6912        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 8, 8, 16)     0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 8, 8, 64)     0           concatenate_13[0][0]             \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 64)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 8, 8, 16)     9216        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 8, 8, 16)     0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 8, 8, 80)     0           concatenate_14[0][0]             \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 80)     320         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 80)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 16)     11520       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 8, 8, 16)     0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 8, 8, 96)     0           concatenate_15[0][0]             \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 96)     384         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 96)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 8, 16)     13824       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 8, 8, 16)     0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 8, 8, 112)    0           concatenate_16[0][0]             \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 8, 112)    448         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 112)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 112)    0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1792)         0           average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           17930       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 187,434\n",
      "Trainable params: 184,522\n",
      "Non-trainable params: 2,912\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xoUjJbZDRcrg"
   },
   "outputs": [],
   "source": [
    "class stop_at_Acc(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,validation_iterator, validation_steps, threshold = 0.85, ):\n",
    "        super(stop_at_Acc, self).__init__()\n",
    "        self.threshold = threshold\n",
    "        self.validation_iterator = validation_iterator\n",
    "        self.validation_steps = validation_steps\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # score = self.model.evaluate_generator(self.validation_iterator,steps=len(self.validation_iterator)) #use for genrator\n",
    "        score = model.evaluate(self.validation_iterator,steps=self.validation_steps, verbose=0)\n",
    "        acc = score[1]\n",
    "        if acc >= self.threshold:\n",
    "            self.model.stop_training = True\n",
    "            print(\"Stopping Training:: Val Acc : %.3f Achieved\"%(acc))\n",
    "            \n",
    "stopper = stop_at_Acc(test_dataset, validation_steps=len_test//batch_size, threshold = 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4XOsW3ahSkL"
   },
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.01,momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "G6z0VO3jGZWP",
    "outputId": "ca0e10a2-88cf-41c2-971c-43688c5a9511"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DatasetV1Adapter shapes: ((?, 32, 32, 3), (?, 10)), types: (tf.float32, tf.int32)>\n",
      "<DatasetV1Adapter shapes: ((?, 32, 32, 3), (?, 10)), types: (tf.float32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "# print(train_input_fn())\n",
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZFf7dPK3gkVT",
    "outputId": "bcbc7e49-fa9e-4585-f3b9-4ad82fc56162"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "781/781 [==============================] - 69s 89ms/step - loss: 1.4173 - acc: 0.4907\n",
      "Epoch 2/75\n",
      "781/781 [==============================] - 53s 67ms/step - loss: 1.0321 - acc: 0.6353\n",
      "Epoch 3/75\n",
      "781/781 [==============================] - 53s 67ms/step - loss: 0.8628 - acc: 0.6953\n",
      "Epoch 4/75\n",
      "781/781 [==============================] - 53s 68ms/step - loss: 0.7665 - acc: 0.7314\n",
      "Epoch 5/75\n",
      "781/781 [==============================] - 53s 68ms/step - loss: 0.6976 - acc: 0.7545\n",
      "Epoch 6/75\n",
      "781/781 [==============================] - 53s 68ms/step - loss: 0.6464 - acc: 0.7728\n",
      "Epoch 7/75\n",
      "781/781 [==============================] - 53s 67ms/step - loss: 0.6050 - acc: 0.7876\n",
      "Epoch 8/75\n",
      "781/781 [==============================] - 53s 68ms/step - loss: 0.5722 - acc: 0.7991\n",
      "Epoch 9/75\n",
      "781/781 [==============================] - 53s 68ms/step - loss: 0.5475 - acc: 0.8098\n",
      "Epoch 10/75\n",
      "781/781 [==============================] - 53s 68ms/step - loss: 0.5206 - acc: 0.8178\n",
      "Epoch 11/75\n",
      "781/781 [==============================] - 53s 68ms/step - loss: 0.4992 - acc: 0.8249\n",
      "Epoch 12/75\n",
      "781/781 [==============================] - 53s 68ms/step - loss: 0.4844 - acc: 0.8296\n",
      "Epoch 13/75\n",
      "781/781 [==============================] - 53s 68ms/step - loss: 0.4606 - acc: 0.8365\n",
      "Epoch 14/75\n",
      "781/781 [==============================] - 53s 68ms/step - loss: 0.4469 - acc: 0.8447\n",
      "Epoch 15/75\n",
      "781/781 [==============================] - 53s 68ms/step - loss: 0.4390 - acc: 0.8474\n",
      "Epoch 16/75\n",
      "781/781 [==============================] - 53s 68ms/step - loss: 0.4224 - acc: 0.8529\n",
      "Epoch 17/75\n",
      "781/781 [==============================] - 53s 68ms/step - loss: 0.4110 - acc: 0.8563\n",
      "Epoch 18/75\n",
      "781/781 [==============================] - 53s 68ms/step - loss: 0.3979 - acc: 0.8607\n",
      "Epoch 19/75\n",
      "781/781 [==============================] - 53s 68ms/step - loss: 0.3895 - acc: 0.8631\n",
      "Epoch 20/75\n",
      "781/781 [==============================] - 53s 68ms/step - loss: 0.3798 - acc: 0.8669\n",
      "Epoch 21/75\n",
      "781/781 [==============================] - 53s 68ms/step - loss: 0.3685 - acc: 0.8715\n",
      "Epoch 22/75\n",
      "781/781 [==============================] - 53s 68ms/step - loss: 0.3608 - acc: 0.8738\n",
      "Epoch 23/75\n",
      "781/781 [==============================] - 53s 68ms/step - loss: 0.3522 - acc: 0.8763\n",
      "Epoch 24/75\n",
      "781/781 [==============================] - 54s 69ms/step - loss: 0.3454 - acc: 0.8785\n",
      "Epoch 25/75\n",
      "781/781 [==============================] - 53s 68ms/step - loss: 0.3382 - acc: 0.8810\n",
      "Epoch 26/75\n",
      "781/781 [==============================] - 54s 69ms/step - loss: 0.3328 - acc: 0.8821\n",
      "Epoch 27/75\n",
      "781/781 [==============================] - 54s 69ms/step - loss: 0.3268 - acc: 0.8849\n",
      "Epoch 28/75\n",
      "781/781 [==============================] - 54s 69ms/step - loss: 0.3189 - acc: 0.8893\n",
      "Epoch 29/75\n",
      "781/781 [==============================] - 54s 69ms/step - loss: 0.3119 - acc: 0.8903\n",
      "Epoch 30/75\n",
      "781/781 [==============================] - 54s 69ms/step - loss: 0.3086 - acc: 0.8922\n",
      "Epoch 31/75\n",
      "781/781 [==============================] - 54s 69ms/step - loss: 0.3035 - acc: 0.8919\n",
      "Epoch 32/75\n",
      "781/781 [==============================] - 54s 69ms/step - loss: 0.2941 - acc: 0.8964\n",
      "Epoch 33/75\n",
      "781/781 [==============================] - 53s 68ms/step - loss: 0.2910 - acc: 0.8974\n",
      "Epoch 34/75\n",
      "781/781 [==============================] - 54s 69ms/step - loss: 0.2882 - acc: 0.8992\n",
      "Epoch 35/75\n",
      "781/781 [==============================] - 54s 69ms/step - loss: 0.2782 - acc: 0.9016\n",
      "Epoch 36/75\n",
      "781/781 [==============================] - 54s 69ms/step - loss: 0.2791 - acc: 0.9001\n",
      "Epoch 37/75\n",
      "781/781 [==============================] - 54s 69ms/step - loss: 0.2757 - acc: 0.9009\n",
      "Epoch 38/75\n",
      "781/781 [==============================] - 54s 69ms/step - loss: 0.2660 - acc: 0.9055\n",
      "Epoch 39/75\n",
      "781/781 [==============================] - 54s 69ms/step - loss: 0.2641 - acc: 0.9068\n",
      "Epoch 40/75\n",
      "781/781 [==============================] - 54s 69ms/step - loss: 0.2626 - acc: 0.9068\n",
      "Epoch 41/75\n",
      "781/781 [==============================] - 54s 70ms/step - loss: 0.2601 - acc: 0.9073\n",
      "Epoch 42/75\n",
      "781/781 [==============================] - 54s 69ms/step - loss: 0.2499 - acc: 0.9110\n",
      "Epoch 43/75\n",
      "781/781 [==============================] - 54s 70ms/step - loss: 0.2523 - acc: 0.9101\n",
      "Epoch 44/75\n",
      "781/781 [==============================] - 54s 69ms/step - loss: 0.2463 - acc: 0.9121\n",
      "Epoch 45/75\n",
      "781/781 [==============================] - 54s 69ms/step - loss: 0.2422 - acc: 0.9136\n",
      "Epoch 46/75\n",
      "781/781 [==============================] - 54s 69ms/step - loss: 0.2378 - acc: 0.9149\n",
      "Epoch 47/75\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.2323 - acc: 0.9158Stopping Training:: Val Acc : 0.854 Achieved\n",
      "781/781 [==============================] - 54s 69ms/step - loss: 0.2324 - acc: 0.9157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f88d159bcf8>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "            train_dataset,\n",
    "            epochs=75,\n",
    "            steps_per_epoch = len_train//batch_size,\n",
    "            # validation_data=test_dataset,\n",
    "            # validation_steps=len_test//batch_size,\n",
    "            verbose = 1,\n",
    "            callbacks = [stopper]\n",
    "                    )\n",
    "#log seed = 64, prefetch=10, buffer_size=8*1024*1024, no descrease (39 sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "v0S-4W48bitV",
    "outputId": "644ded3d-c409-4765-c73c-246d8d45d504"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "156/156 [==============================] - 2s 15ms/step - loss: 1.4216 - acc: 0.5203\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 1.4720 - acc: 0.4687\n",
      "Epoch 2/75\n",
      "156/156 [==============================] - 2s 15ms/step - loss: 1.0563 - acc: 0.6287\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 1.0808 - acc: 0.6158\n",
      "Epoch 3/75\n",
      "156/156 [==============================] - 2s 15ms/step - loss: 0.8587 - acc: 0.7068\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8911 - acc: 0.6861\n",
      "Epoch 4/75\n",
      "156/156 [==============================] - 2s 15ms/step - loss: 0.7588 - acc: 0.7353\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.7853 - acc: 0.7259\n",
      "Epoch 5/75\n",
      "156/156 [==============================] - 2s 15ms/step - loss: 0.8085 - acc: 0.7217\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.7189 - acc: 0.7479\n",
      "Epoch 6/75\n",
      "156/156 [==============================] - 2s 15ms/step - loss: 0.6474 - acc: 0.7753\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6701 - acc: 0.7651\n",
      "Epoch 7/75\n",
      "156/156 [==============================] - 2s 15ms/step - loss: 0.5949 - acc: 0.7977\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6266 - acc: 0.7799\n",
      "Epoch 8/75\n",
      "156/156 [==============================] - 2s 15ms/step - loss: 0.5725 - acc: 0.8036\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5945 - acc: 0.7911\n",
      "Epoch 9/75\n",
      "156/156 [==============================] - 2s 15ms/step - loss: 0.6559 - acc: 0.7766\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5664 - acc: 0.8016\n",
      "Epoch 10/75\n",
      "156/156 [==============================] - 2s 15ms/step - loss: 0.5785 - acc: 0.8041\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5395 - acc: 0.8132\n",
      "Epoch 11/75\n",
      "156/156 [==============================] - 2s 15ms/step - loss: 0.4983 - acc: 0.8272\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5212 - acc: 0.8182\n",
      "Epoch 12/75\n",
      "156/156 [==============================] - 2s 15ms/step - loss: 0.5470 - acc: 0.8108\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4995 - acc: 0.8256\n",
      "Epoch 13/75\n",
      "156/156 [==============================] - 2s 15ms/step - loss: 0.5737 - acc: 0.8119\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4812 - acc: 0.8315\n",
      "Epoch 14/75\n",
      "156/156 [==============================] - 2s 15ms/step - loss: 0.4896 - acc: 0.8348\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4669 - acc: 0.8374\n",
      "Epoch 15/75\n",
      "156/156 [==============================] - 2s 15ms/step - loss: 0.4392 - acc: 0.8504\n",
      "Stopping Training:: Val Acc : 0.850 Achieved\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4511 - acc: 0.8416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fde769e8860>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log seed = 50, prefetch=4, reduce by 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "crhGk7kEhXAz",
    "outputId": "54836139-1a74-453e-ebbe-8a2a3610f47d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "156/156 [==============================] - 4s 28ms/step - loss: 0.6155 - acc: 0.8007\n",
      "781/781 [==============================] - 88s 112ms/step - loss: 0.5232 - acc: 0.8164\n",
      "Epoch 2/75\n",
      "156/156 [==============================] - 5s 29ms/step - loss: 0.4874 - acc: 0.8342\n",
      "781/781 [==============================] - 84s 108ms/step - loss: 0.5047 - acc: 0.8226\n",
      "Epoch 3/75\n",
      "156/156 [==============================] - 5s 32ms/step - loss: 0.4918 - acc: 0.8348\n",
      "781/781 [==============================] - 85s 109ms/step - loss: 0.4876 - acc: 0.8278\n",
      "Epoch 4/75\n",
      "156/156 [==============================] - 4s 29ms/step - loss: 0.4296 - acc: 0.8512\n",
      "Stopping Training:: Val Acc : 0.851 Achieved\n",
      "781/781 [==============================] - 84s 108ms/step - loss: 0.4733 - acc: 0.8356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f77d3ef2da0>"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log for seed=2, prefetch=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZcWydmIVhZGr",
    "outputId": "4a1b2714-a32a-4df0-d38c-63c55b32313a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19/156 [==>...........................] - ETA: 5:50 - loss: 0.6259 - acc: 0.8150"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "score = model.evaluate(test_dataset, steps=len_test//batch_size)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UE3lF6EH1r_L"
   },
   "outputs": [],
   "source": [
    "# Save the trained weights in to .h5 format\n",
    "model.save_weights(\"DNST_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ai-yZ2ED5AK1"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download('DNST_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DUGek1zFdd2H"
   },
   "source": [
    "# for time comparision(without TFRecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EpQ7ZzcbdSjg"
   },
   "outputs": [],
   "source": [
    "class stop_at_Acc(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,validation_iterator, threshold = 0.85, ):\n",
    "        super(stop_at_Acc, self).__init__()\n",
    "        self.threshold = threshold\n",
    "        self.validation_iterator = validation_iterator\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        score = self.model.evaluate_generator(self.validation_iterator, steps=len(self.validation_iterator))\n",
    "        acc = score[1]\n",
    "        if acc >= self.threshold:\n",
    "            self.model.stop_training = True\n",
    "            print(\"Stopping Training:: Val Acc : %.3f Achieved\"%(acc))\n",
    "            \n",
    "stopper = stop_at_Acc(validation_iterator, threshold = 0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fUCOUkzoC4Fm",
    "outputId": "7eac2b35-8508-4749-9f75-8f0ba5eafd9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Og56VCRh5j8V"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "datagen = ImageDataGenerator()\n",
    "datagen.fit(X_train)\n",
    "\n",
    "y_train = to_categorical(Y_train, num_classes=10, dtype='float32')\n",
    "y_test = to_categorical(Y_test, num_classes=10, dtype='float32')\n",
    "datagen_validation = ImageDataGenerator(featurewise_center=False,\n",
    "                                        featurewise_std_normalization=False,\n",
    "                                        )\n",
    "\n",
    "\n",
    "validation_iterator = datagen_validation.flow(X_test, y_test, batch_size=batch_size,shuffle=True)\n",
    "\n",
    "train_iterator = datagen.flow(X_train, y_train, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xILKh_ALB8We",
    "outputId": "d0832746-53a6-4679-d617-949e44b5ea2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "n2BpTO8UdRdS",
    "outputId": "5ad56659-4339-4561-ed9b-0f42b5b1c800"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "781/781 [==============================] - 97s 124ms/step - loss: 0.7160 - acc: 0.7494 - val_loss: 1.1623 - val_acc: 0.6544\n",
      "Epoch 2/2\n",
      "781/781 [==============================] - 97s 124ms/step - loss: 0.6649 - acc: 0.7663 - val_loss: 0.8300 - val_acc: 0.7323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fea5e75f860>"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_iterator,\n",
    "                    steps_per_epoch=len_train//batch_size, \n",
    "                    validation_data = validation_iterator, \n",
    "                    validation_steps = len_test//batch_size,\n",
    "                    epochs=2,\n",
    "                    verbose=1,\n",
    "                    # callbacks=[stopper]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CTd7Ym4gHE1W"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(validation_iterator, steps=len(validation_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "T8UOMiwhBKd9",
    "outputId": "9f64d2d8-92f5-41db-e325-de51be0e3920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 98s 2ms/sample - loss: 1.4700 - acc: 0.4740\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 90s 2ms/sample - loss: 1.0425 - acc: 0.6300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fea69f01400>"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=64, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ffhsg1N5DXsD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Session_16_DNST_CIFAR10_AUG.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
